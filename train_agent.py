import os
import time
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback # <-- –î–æ–±–∞–≤–∏–ª–∏
from stable_baselines3.common.monitor import Monitor

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à—É —Å—Ä–µ–¥—É
from gym_environment import IEEE123Env

# --- –ù–ê–°–¢–†–û–ô–ö–ò –ü–£–¢–ï–ô ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_DIR = os.path.join(BASE_DIR, "training_logs")
MODEL_DIR = os.path.join(BASE_DIR, "trained_models")
CHECKPOINT_DIR = os.path.join(MODEL_DIR, "checkpoints") # –ü–∞–ø–∫–∞ –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π

os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

TIMESTEPS = 100_000

class TensorboardCallback(BaseCallback):
    def __init__(self, verbose=0):
        super(TensorboardCallback, self).__init__(verbose)

    def _on_step(self) -> bool:
        infos = self.locals.get("infos", [{}])[0]
        if "power_kw" in infos:
            self.logger.record("custom/power_kw", infos["power_kw"])
        if "switches" in infos:
            self.logger.record("custom/switches", infos["switches"])
        return True

def main():
    print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è...")
    print(f"üìÇ –õ–æ–≥–∏: {LOG_DIR}")
    print(f"üíæ –ß–µ–∫–ø–æ–∏–Ω—Ç—ã: {CHECKPOINT_DIR}")

    def make_env():
        env = IEEE123Env()
        log_file = os.path.join(LOG_DIR, "monitor") 
        env = Monitor(env, log_file) 
        return env

    env = DummyVecEnv([make_env])

    model = PPO(
        "MlpPolicy", 
        env, 
        verbose=1, 
        tensorboard_log=LOG_DIR,
        learning_rate=0.0003,
        n_steps=2048,
        batch_size=64,
        gamma=0.99
    )

    print(f"üß† –°—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {TIMESTEPS} —à–∞–≥–æ–≤...")
    start_time = time.time()

    # --- –°–û–ó–î–ê–ï–ú –ß–ï–ö–ü–û–ò–ù–¢-–ö–û–õ–õ–ë–ï–ö ---
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∫–∞–∂–¥—ã–µ 10 000 —à–∞–≥–æ–≤
    checkpoint_callback = CheckpointCallback(
        save_freq=10000, 
        save_path=CHECKPOINT_DIR,
        name_prefix="ppo_ieee123"
    )

    # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–ª–±–µ–∫–æ–≤ (–Ω–∞—à –ª–æ–≥–≥–µ—Ä + —á–µ–∫–ø–æ–∏–Ω—Ç–µ—Ä)
    model.learn(
        total_timesteps=TIMESTEPS, 
        callback=[TensorboardCallback(), checkpoint_callback],
        progress_bar=True,
        tb_log_name="PPO_run"
    )

    end_time = time.time()
    print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {(end_time - start_time)/60:.1f} –º–∏–Ω—É—Ç.")

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    final_path = os.path.join(MODEL_DIR, "ppo_ieee123_final")
    model.save(final_path)
    print(f"üíæ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_path}.zip")

if __name__ == "__main__":
    main()